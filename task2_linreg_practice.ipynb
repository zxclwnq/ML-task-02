{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ Линейная регрессия\n",
    "\n",
    "В данном задании мы рассмотрим набор данных об учащихся, собранный в 2006 году в одной из школ Португалии. Данные представлены в неудобном для машинного обучения виде, и содержат мусор. Ваша задача &mdash; привести их к надлежащему виду и обучить на них простую модель.\n",
    "\n",
    "Данные состоят из четырех файлов:\n",
    "- data.csv &mdash; основная таблица с информацией о учащихся\n",
    "- scores.csv &mdash; список финальных оценок по одному из предметов (20-балльная шкала переведенная в проценты)\n",
    "- attendance.csv &mdash; таблица посещений занятий по этому предмету\n",
    "- school_support.txt &mdash; список учащихся, которым оказывается финансовая поддержка\n",
    "\n",
    "Ваша задача &mdash; построить модель для предсказания финальных оценок исходя из всех остальных данных и проверить качество ее работы с помощью кросс-валидации. В качестве алгоритма мы будем использовать линейную регрессию\n",
    "\n",
    "Расшифровка столбцов в data.csv для справки:\n",
    "- age &mdash; возраст\n",
    "- Medu &mdash; уровень образования матери (по некоторой условной шкале)\n",
    "- Fedu &mdash; уровень образования отца (по некоторой условной шкале)\n",
    "- traveltime &mdash; время в пути до школы (1 – < 15 мин., 2 – от 15 до 30 мин., 3 – от 30 мин. to 1 ч.\n",
    "или 4 – > 1 ч.)\n",
    "- studytime &mdash; время, затрачиваемое на занятия вне школы (1 – < 2 ч., 2 – от 2 до 5 ч., 3 – от 5 до 10 ч. или 4 – > 10 ч.)\n",
    "- famrel &mdash; насколько хорошие отношения в семье у учащегося (по некоторой условной шкале)\n",
    "- freetime &mdash; количество свободного времени вне школы (по некоторой условной шкале)\n",
    "- goout &mdash; время, затрачиваемое на общение с друзьями (по некоторой условной шкале)\n",
    "- Dalc &mdash; количество употребления алкоголя в учебные дни (по некоторой условной шкале)\n",
    "- Walc &mdash; количество употребления алкоголя в неучебные дни (по некоторой условной шкале)\n",
    "- health &mdash; уровень здоровья (по некоторой условной шкале)\n",
    "- sex_M &mdash; пол: мужской (1) или женский (0)\n",
    "- address_U &mdash; живет ли учащийся в городе (1) или в пригороде (0)\n",
    "- famsize_LE3 &mdash; размер семьи: не больше 3 человек (1) или больше (0)\n",
    "- Pstatus_T &mdash; живут ли родители вместе (1) или отдельно (0)\n",
    "- nursery &mdash; посещал ли учащийся детский сад\n",
    "- plans_university &mdash; планирует ли учащийся поступать в университет (-1 или 1)\n",
    "- past_failures &mdash; количество неудовлетворительных оценок по другим предметам ранее (от 0 до 4)\n",
    "\n",
    "*Примечание. Несколько признаков в данных содержат ошибки/проблемы/некорректности. Эти проблемы нужно исправить. Для\n",
    "проверки &mdash; всего в данных таких проблем четыре.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: сломанный признак (а может и не один)\n",
    "__(1 балл)__\n",
    "\n",
    "Загрузите таблицу data.csv.\n",
    "\n",
    "Найдите в данных сломанный признак (он не соответствует описанию) и исправьте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\AppData\\Local\\Temp\\ipykernel_11108\\2142278957.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '10' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, s] = str(data.loc[i, s])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  Medu  Fedu  traveltime  studytime  famrel  freetime  goout  Dalc  \\\n",
      "0     16     4     4           1          2       5         4    4.0   1.0   \n",
      "1     17     4     4           1          1       5         3    4.0   1.0   \n",
      "2     16     1     1           2          1       4         5    5.0   2.0   \n",
      "3     18     1     2           2          1       3         4    4.0   2.0   \n",
      "4     17     2     1           2          2       4         2    5.0   1.0   \n",
      "..   ...   ...   ...         ...        ...     ...       ...    ...   ...   \n",
      "644   18     2     2           4          2       4         2    5.0   1.0   \n",
      "645   15     4     4           2          2       4         3    1.0   1.0   \n",
      "646   21     1     1           2          2       5         3    3.0   5.0   \n",
      "647   16     2     2           1          1       4         3    4.0   1.0   \n",
      "648   16     2     3          40          2       4         5    4.0   1.0   \n",
      "\n",
      "     Walc  health  sex_M  address_U  famsize_LE3  Pstatus_T  nursery  \\\n",
      "0     2.0       5      1          1            0          1        1   \n",
      "1     2.0       5      0          1            0          1        1   \n",
      "2     4.0       5      1          0            1          1        1   \n",
      "3     4.0       4      1          1            0          1        0   \n",
      "4     2.0       5      0          0            0          1        1   \n",
      "..    ...     ...    ...        ...          ...        ...      ...   \n",
      "644   1.0       2      0          1            0          1        1   \n",
      "645   1.0       5      1          1            0          1        1   \n",
      "646   2.0       4      1          0            1          1        1   \n",
      "647   2.0       1      0          1            1          0        1   \n",
      "648   2.0       1      0          0            0          1        1   \n",
      "\n",
      "    plans_university past_failures  \n",
      "0                  1             0  \n",
      "1                  1             0  \n",
      "2                  1             0  \n",
      "3                 -1             0  \n",
      "4                  1             0  \n",
      "..               ...           ...  \n",
      "644                1             0  \n",
      "645                1             0  \n",
      "646               -1             2  \n",
      "647               -1             0  \n",
      "648                1             0  \n",
      "\n",
      "[649 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "check = []\n",
    "INF = 1e18\n",
    "rows = 649\n",
    "\n",
    "pl = 'plans_university'\n",
    "pf = 'past_failures'\n",
    "s = pl + pf\n",
    "\n",
    "for i in range(rows):\n",
    "    if data.loc[i, s] < 0:\n",
    "        check.append(True)\n",
    "        data.loc[i, s] *= -1\n",
    "        data.loc[i, s] = str(data.loc[i, s])\n",
    "        data.loc[i, s] = data.loc[i, s][0] + '*' + data.loc[i, s][1]\n",
    "    else:\n",
    "        check.append(False)\n",
    "        data.loc[i, s] = str(data.loc[i, s])\n",
    "        data.loc[i, s] = data.loc[i, s][0] + '*' + data.loc[i, s][1]\n",
    "\n",
    "plpf = data[s].str.split('*', expand=True)\n",
    "\n",
    "plpf.columns = [pl, pf]\n",
    "\n",
    "data = pd.concat([data, plpf], axis=1)\n",
    "\n",
    "data = data.drop(s, axis=1)\n",
    "\n",
    "for i in range(rows):\n",
    "    data.loc[i, pf] = int(data.loc[i, pf])\n",
    "    data.loc[i, pl] = int(data.loc[i, pl])\n",
    "    if check[i]:\n",
    "        data.loc[i, pl] *= -1\n",
    "\n",
    "for i in range(rows):\n",
    "    if data.loc[i, 'age'] > 100:\n",
    "        data.loc[i, 'age'] = 2006 - data.loc[i, 'age']\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2: пропуски в данных \n",
    "__(1 балл)__\n",
    "\n",
    "Проверьте, есть ли в данных пропуски (значения NaN). Замените все пропущенные значения на среднее значение этого признака по столбцу.\n",
    "\n",
    "*Hint: изучите в pandas функции loc, isnull, а также передачу булевых массивов в качестве индексов.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  Medu  Fedu  traveltime  studytime  famrel  freetime  goout  Dalc  \\\n",
      "0     16     4     4           1          2       5         4    4.0   1.0   \n",
      "1     17     4     4           1          1       5         3    4.0   1.0   \n",
      "2     16     1     1           2          1       4         5    5.0   2.0   \n",
      "3     18     1     2           2          1       3         4    4.0   2.0   \n",
      "4     17     2     1           2          2       4         2    5.0   1.0   \n",
      "..   ...   ...   ...         ...        ...     ...       ...    ...   ...   \n",
      "644   18     2     2           4          2       4         2    5.0   1.0   \n",
      "645   15     4     4           2          2       4         3    1.0   1.0   \n",
      "646   21     1     1           2          2       5         3    3.0   5.0   \n",
      "647   16     2     2           1          1       4         3    4.0   1.0   \n",
      "648   16     2     3          40          2       4         5    4.0   1.0   \n",
      "\n",
      "     Walc  health  sex_M  address_U  famsize_LE3  Pstatus_T  nursery  \\\n",
      "0     2.0       5      1          1            0          1        1   \n",
      "1     2.0       5      0          1            0          1        1   \n",
      "2     4.0       5      1          0            1          1        1   \n",
      "3     4.0       4      1          1            0          1        0   \n",
      "4     2.0       5      0          0            0          1        1   \n",
      "..    ...     ...    ...        ...          ...        ...      ...   \n",
      "644   1.0       2      0          1            0          1        1   \n",
      "645   1.0       5      1          1            0          1        1   \n",
      "646   2.0       4      1          0            1          1        1   \n",
      "647   2.0       1      0          1            1          0        1   \n",
      "648   2.0       1      0          0            0          1        1   \n",
      "\n",
      "     plans_university  past_failures  \n",
      "0                   1              0  \n",
      "1                   1              0  \n",
      "2                   1              0  \n",
      "3                  -1              0  \n",
      "4                   1              0  \n",
      "..                ...            ...  \n",
      "644                 1              0  \n",
      "645                 1              0  \n",
      "646                -1              2  \n",
      "647                -1              0  \n",
      "648                 1              0  \n",
      "\n",
      "[649 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna(data.mean())\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3: нормализация данных\n",
    "__(1 балл)__\n",
    "\n",
    "Нормализуйте данные любым способом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  Medu  Fedu  traveltime  studytime  famrel  freetime  goout  \\\n",
      "0    0.142857  1.00  1.00    0.000000   0.333333    1.00      0.75   0.75   \n",
      "1    0.285714  1.00  1.00    0.000000   0.000000    1.00      0.50   0.75   \n",
      "2    0.142857  0.25  0.25    0.020408   0.000000    0.75      1.00   1.00   \n",
      "3    0.428571  0.25  0.50    0.020408   0.000000    0.50      0.75   0.75   \n",
      "4    0.285714  0.50  0.25    0.020408   0.333333    0.75      0.25   1.00   \n",
      "..        ...   ...   ...         ...        ...     ...       ...    ...   \n",
      "644  0.428571  0.50  0.50    0.061224   0.333333    0.75      0.25   1.00   \n",
      "645  0.000000  1.00  1.00    0.020408   0.333333    0.75      0.50   0.00   \n",
      "646  0.857143  0.25  0.25    0.020408   0.333333    1.00      0.50   0.50   \n",
      "647  0.142857  0.50  0.50    0.000000   0.000000    0.75      0.50   0.75   \n",
      "648  0.142857  0.50  0.75    0.795918   0.333333    0.75      1.00   0.75   \n",
      "\n",
      "     Dalc  Walc  health  sex_M  address_U  famsize_LE3  Pstatus_T  nursery  \\\n",
      "0    0.00  0.25    1.00    1.0        1.0          0.0        1.0      1.0   \n",
      "1    0.00  0.25    1.00    0.0        1.0          0.0        1.0      1.0   \n",
      "2    0.25  0.75    1.00    1.0        0.0          1.0        1.0      1.0   \n",
      "3    0.25  0.75    0.75    1.0        1.0          0.0        1.0      0.0   \n",
      "4    0.00  0.25    1.00    0.0        0.0          0.0        1.0      1.0   \n",
      "..    ...   ...     ...    ...        ...          ...        ...      ...   \n",
      "644  0.00  0.00    0.25    0.0        1.0          0.0        1.0      1.0   \n",
      "645  0.00  0.00    1.00    1.0        1.0          0.0        1.0      1.0   \n",
      "646  1.00  0.25    0.75    1.0        0.0          1.0        1.0      1.0   \n",
      "647  0.00  0.25    0.00    0.0        1.0          1.0        0.0      1.0   \n",
      "648  0.00  0.25    0.00    0.0        0.0          0.0        1.0      1.0   \n",
      "\n",
      "     plans_university  past_failures  \n",
      "0                 1.0       0.000000  \n",
      "1                 1.0       0.000000  \n",
      "2                 1.0       0.000000  \n",
      "3                 0.0       0.000000  \n",
      "4                 1.0       0.000000  \n",
      "..                ...            ...  \n",
      "644               1.0       0.000000  \n",
      "645               1.0       0.000000  \n",
      "646               0.0       0.666667  \n",
      "647               0.0       0.000000  \n",
      "648               1.0       0.000000  \n",
      "\n",
      "[649 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "data = (data - data.min()) / (data.max() - data.min())   \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4: кросс-валидация для исходных данных\n",
    "__(1 балл)__\n",
    "\n",
    "Загрузите файл scores.csv и протестируйте, как линейная регрессия предсказывает ответ сейчас (с помощью кросс-валидации).\n",
    "\n",
    "Кроссвалидацию сделайте по 4 разбивкам. Выведите качество в каждом их разбиений.\n",
    "\n",
    "*Hint: воспользуйтесь sklearn.linear_model и sklearn.model_selection.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24687854, 0.26409667, 0.16157011, 0.22620673])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('scores.csv', header=None)\n",
    "scores.columns = ['score']\n",
    "x = data.values\n",
    "y = scores.values\n",
    "model = LinearRegression()\n",
    "res = cross_validate(model, x, y, cv = 4)\n",
    "res['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5: полные данные\n",
    "__(2 балла)__\n",
    "\n",
    "Воспользуйтесь файлами attendance.csv и school_support.txt для того, чтобы добавить новые признаки в данные. Желательно по максимуму использовать возможности pandas для упрощения преобразований.\n",
    "\n",
    "school_suport число в строке значит что i-ый школьник из исходной таблицы получал мат помощь (обратите внимание что строк в файле меньше, подумайте как правильно импортировать данные)\n",
    "\n",
    "Добавьте данные таким образом, чтобы качество выросло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attend = pd.read_csv('attendance.csv', delimiter = \";\")\n",
    "support = pd.read_table('school_support.txt', header=None)\n",
    "support.columns = ['support']\n",
    "a = []\n",
    "\n",
    "for j in range(rows):\n",
    "    cnt = 0\n",
    "    for i in attend.columns:\n",
    "        cnt += attend.loc[j, i] == '+'\n",
    "    a.append(cnt)\n",
    "\n",
    "data['attend'] = a\n",
    "\n",
    "a = [0] * rows\n",
    "\n",
    "for i in range(len(support)):\n",
    "    a[support.loc[i, 'support']] = 1\n",
    "\n",
    "data['support'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 6: борьба с выбросами\n",
    "__(1.5 балла)__\n",
    "\n",
    "Качество предсказания может ухудшаться, если в данных присутствуют корректные значения признаков (с точки зрения чтения данных и применения методов), но не соответствующие реальным объектам. Например, данные могли быть введены в неверном формате, а потом слишком грубо приведены к общему виду, из-за чего ошибка не была замечена.\n",
    "Попробуем от такого избавиться &mdash; а для этого такие объекты нужно сначала найти. Конечно, нам еще недоступны многие продвинутые способы, но давайте попробуем обойтись простыми.\n",
    "\n",
    "Первый способ это сделать &mdash; посмотреть для каждого признака на распределение его значений и проверить крайние значения на правдоподобность. (постройте гистограммы для признаков, как минимум для подозрительных)\n",
    "\n",
    "*Hint 1: используйте функцию DataFrame.hist*\n",
    "\n",
    "*Hint 2: в описании датасета выше есть информация, необходимая для восстановления правильных значений*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'traveltime'\n",
    "\n",
    "for i in range(rows):\n",
    "    if data.loc[i, s] > 4:\n",
    "        if data.loc[i, s] < 15:\n",
    "            data.loc[i, s] = 1\n",
    "        elif data.loc[i, s] < 30:\n",
    "            data.loc[i, s] = 2\n",
    "        elif data.loc[i, s] < 60:\n",
    "            data.loc[i, s] = 3\n",
    "        else:\n",
    "            data.loc[i, s] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1.5 балла)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой простой способ найти выбросы &mdash; сделать предсказание и посчитать ошибку на каждом объекте по отдельности и посмотреть на объекты с наибольшей ошибкой. Обучите линейную регрессию (функция fit) и для каждого объекта посчитайте среднеквадратичное отклонение. Постройте гистограмму распределения ошибок. Посмотрите на гистограмму и удалите из выборки те объекты на которых ошибка слишком большая.\n",
    "\n",
    "Обратите внимание, что просто удалять все объекты с высокой ошибкой нельзя &mdash; это, конечно, хороший способ добиться меньшей ошибки (на данной выборке), но одновременно вы ухудшите обобщающую способность алгоритма. Вместо этого вам нужно найти однозначно ошибочные записи и их исправить.\n",
    "\n",
    "*Hint: возможно, все проблемы уже были найдены первым способом; для проверки &mdash; в сумме здесь нужно исправить 3 проблемы.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска ошибки на одном отдельном обьекте придётся обучить линейную регрессию руками. Частичный пример, допишите код. Постройте гистограмму распределения ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4100.433948727987, 4055.732207129531, 4036.64931787305, 4030.298354787557, 4030.298354787557, 4011.2754655310755, 3485.0876401786218, 1523.7024059811613, 1158.3560974317963, 1158.3560974317963, 1158.3560974317963, 958.8540862900501, 958.8540862900501, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 843.0097888824312, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 674.2003948394151, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 577.6634803330661, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 439.54670338878026, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 362.317171783701, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 254.89301193814535, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 196.9708632343359, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 120.23932048751044, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 81.6245546849708, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 35.585629036875524, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 16.278246135605706, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154, 0.9319375862406154]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "scores = pd.read_csv('scores.csv', header=None)\n",
    "scores.columns = ['score']\n",
    "x = data.values\n",
    "y = scores.values\n",
    "regression = LinearRegression()\n",
    "regression = regression.fit(x, y)\n",
    "error = []\n",
    "for i in x:\n",
    "    j = [i]\n",
    "    prediction = regression.predict(j)\n",
    "    error.append((prediction[0] - y) ** 2)\n",
    "array_of_errors = []\n",
    "\n",
    "for i in error[0]:\n",
    "    array_of_errors.append(i[0])\n",
    "\n",
    "array_of_errors.sort()\n",
    "array_of_errors.reverse()\n",
    "\n",
    "print(array_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27308425, 0.27895267, 0.13042846, 0.2278476 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('scores.csv', header=None)\n",
    "scores.columns = ['score']\n",
    "model = LinearRegression()\n",
    "res = cross_validate(model, data.values, scores.values, cv = 4)\n",
    "res['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальное предсказание и отчёт (1 балл)\n",
    "\n",
    "Проведите предсказание еще раз и сравните качество с исходным. Запишите свои наблюдения - как изменялось качество обучения модели при использовании разных модификаций данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27308425, 0.27895267, 0.13042846, 0.2278476 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv('scores.csv', header=None)\n",
    "scores.columns = ['score']\n",
    "model = LinearRegression()\n",
    "res = cross_validate(model, data.values, scores.values, cv = 4)\n",
    "res['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "Худо-бедно написал линрег, качество ужасное, данных мало, ~~расширять не умеем ещё~~, всё грустно в жизни"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
